{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.conjugate_bayes_lin_reg import NormalInverseGammaPriorLinearRegression\n",
    "from src.models.bayesian_nn import BayesianNN\n",
    "from src.utils import id\n",
    "from src.utils import _torch_expy2 as expy2\n",
    "from src.utils import _torch_l1_projection as l1_projection\n",
    "\n",
    "from src.attacks.point_attacks import attack, attack_fgsm\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\", palette=\"muted\", font=\"serif\")\n",
    "\n",
    "sns.set_context(\"notebook\", font_scale=1.5, rc={\"lines.linewidth\": 2.5})\n",
    "plt.rcParams.update({\n",
    "    'axes.titlesize': 18,\n",
    "    'axes.labelsize': 16,\n",
    "    'xtick.labelsize': 12,\n",
    "    'ytick.labelsize': 12,\n",
    "    'axes.titleweight': 'bold',\n",
    "    'axes.edgecolor': 'black',\n",
    "    'axes.linewidth': 1,\n",
    "    'grid.alpha': 0.5,\n",
    "    'grid.linestyle': '--',\n",
    "    'legend.fontsize': 12,\n",
    "    'legend.frameon': False,\n",
    "    'figure.dpi': 300,  \n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set all seeds for reproducibility\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wine dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wine Quality dataset with response in {3, 4, 5, 6, 7, 8}, 11 features and 4898 samples\n",
    "\n",
    "# URL to the Wine Quality dataset (for example, from UCI Machine Learning Repository)\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-white.csv\"\n",
    "# Load the dataset directly into a Pandas DataFrame\n",
    "data = pd.read_csv(url, delimiter=\";\")\n",
    "\n",
    "X = data.iloc[:, :-1].values\n",
    "y = data.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the data\n",
    "scaler = MinMaxScaler()\n",
    "X_normalized = scaler.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_normalized, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"X_train shape: {X_train.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpyro\n",
    "numpyro.set_host_device_count(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model\n",
    "model = BayesianNN(input_dim=X_train.shape[1], hidden_units=3)\n",
    "try:\n",
    "    model.load('../src/models/bayesian_3nn')\n",
    "except FileNotFoundError:   \n",
    "    print('Not model found, fitting the model') \n",
    "    model.fit(\n",
    "        X_train, \n",
    "        y_train,\n",
    "        num_warmup=500,\n",
    "        num_samples=1000,\n",
    "        num_chains=8,\n",
    "    )\n",
    "    model.save('../src/models/bayesian_3nn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 100\n",
    "all_importances = []\n",
    "for i in range(100):\n",
    "    x = torch.tensor(X_test[i,:].copy(), dtype=torch.float32).unsqueeze(1)\n",
    "    baseline_pred = model.sample_predictive_distribution(x, n_samples).mean()\n",
    "    baseline_score = (y_test[i] - baseline_pred) ** 2\n",
    "\n",
    "    importances = []\n",
    "    for j in range(X_test.shape[1]):\n",
    "        scores = []\n",
    "        X_mod = x.clone()\n",
    "        X_mod[j, :] += np.random.uniform(-0.2, 0.2)\n",
    "        preds = model.sample_predictive_distribution(X_mod, n_samples).mean()\n",
    "        score = (y_test[i] - preds) ** 2\n",
    "        importances.append(score - baseline_score)\n",
    "\n",
    "    all_importances.append(importances)\n",
    "all_importances = np.array(all_importances)\n",
    "importances = all_importances.mean(axis=0)\n",
    "# Features by importance\n",
    "importances = np.array(importances)\n",
    "indices = np.argsort(importances)[::-1]\n",
    "# Print the feature ranking\n",
    "print(\"Feature ranking:\")\n",
    "for f in range(X_test.shape[1]):\n",
    "    print(f\"{f + 1}. Feature {indices[f]} ({importances[indices[f]]})\")\n",
    "\n",
    "# TOP 7 features\n",
    "TOP_FEATURES = list(indices[:7])\n",
    "# worse 7 features\n",
    "WORSE_FEATURES = list(indices[-7:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the attacker model: Different arquitecture\n",
    "attack_model1 = BayesianNN(input_dim=X_train.shape[1], hidden_units=4)\n",
    "try:\n",
    "    attack_model1.load('../src/models/bayesian_4nn')\n",
    "except FileNotFoundError:   \n",
    "    print('Not model found, fitting the model') \n",
    "    attack_model1.fit(\n",
    "        X_train, \n",
    "        y_train,\n",
    "        num_warmup=500,\n",
    "        num_samples=1000,\n",
    "        num_chains=8,\n",
    "    )\n",
    "    attack_model1.save('../src/models/bayesian_4nn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the attacker model: Smaller dataset\n",
    "attack_model2 = BayesianNN(input_dim=X_train.shape[1], hidden_units=4)\n",
    "X_train_subset = X_train[:1000]\n",
    "y_train_subset = y_train[:1000]\n",
    "try:\n",
    "    attack_model2.load('../src/models/bayesian_3nn_small')\n",
    "except FileNotFoundError:   \n",
    "    print('Not model found, fitting the model') \n",
    "    attack_model2.fit(\n",
    "        X_train_subset, \n",
    "        y_train_subset,\n",
    "        num_warmup=500,\n",
    "        num_samples=1000,\n",
    "        num_chains=8,\n",
    "    )\n",
    "    attack_model2.save('../src/models/bayesian_3nn_small')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the attacker model: Not all features\n",
    "X_train_subset = X_train[:, TOP_FEATURES]\n",
    "attack_model3 = BayesianNN(input_dim=X_train_subset.shape[1], hidden_units=3)\n",
    "try:\n",
    "    attack_model3.load('../src/models/bayesian_3nn_topfeatures')\n",
    "except FileNotFoundError:   \n",
    "    print('Not model found, fitting the model') \n",
    "    attack_model3.fit(\n",
    "        X_train_subset, \n",
    "        y_train,\n",
    "        num_warmup=500,\n",
    "        num_samples=1000,\n",
    "        num_chains=8,\n",
    "    )\n",
    "    attack_model3.save('../src/models/bayesian_3nn_topfeatures')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the attacker model: Not all features\n",
    "X_train_subset = X_train[:, WORSE_FEATURES]\n",
    "attack_model4 = BayesianNN(input_dim=X_train_subset.shape[1], hidden_units=3)\n",
    "try:\n",
    "    attack_model4.load('../src/models/bayesian_3nn_worsefeatures')\n",
    "except FileNotFoundError:   \n",
    "    print('Not model found, fitting the model') \n",
    "    attack_model4.fit(\n",
    "        X_train_subset, \n",
    "        y_train,\n",
    "        num_warmup=500,\n",
    "        num_samples=1000,\n",
    "        num_chains=8,\n",
    "    )\n",
    "    attack_model4.save('../src/models/bayesian_3nn_worsefeatures')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attack with exp(y^2/100) as objective function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot loss as a function of the size of the perturbation for reparametrization trick attack\n",
    "x_adv = torch.tensor(X_test[17, :].copy(), dtype=torch.float32, requires_grad=True)\n",
    "y_star = 3.0\n",
    "losses_original_rep = []\n",
    "losses_total_rep1 = []\n",
    "losses_total_rep2 = []\n",
    "losses_total_rep3 = []\n",
    "losses_total_rep4 = []\n",
    "epsilons = np.linspace(0, .5, 6)\n",
    "\n",
    "\n",
    "def compute_loss_rep(epsilon, attack_model):\n",
    "    if attack_model == attack_model3:\n",
    "        x_adv = torch.tensor(X_test[17, TOP_FEATURES].copy(), dtype=torch.float32, requires_grad=True)\n",
    "        x_adv_original = np.array(X_test[17, :].copy(), dtype=np.float32)\n",
    "    elif attack_model == attack_model4:\n",
    "        x_adv = torch.tensor(X_test[17, WORSE_FEATURES].copy(), dtype=torch.float32, requires_grad=True)\n",
    "        x_adv_original = np.array(X_test[17, :].copy(), dtype=np.float32)\n",
    "    else:\n",
    "        x_adv = torch.tensor(X_test[17, :].copy(), dtype=torch.float32, requires_grad=True)\n",
    "    x_adv_values, loss_values, func_values = attack(x_adv, attack_model, y_star, epsilon=epsilon, learning_rate=1e-4, num_iterations=1000, samples_per_iteration=1000, func=expy2)    \n",
    "    if attack_model == attack_model3:\n",
    "        x_adv_original[TOP_FEATURES] = x_adv_values[-1]\n",
    "        y_adv = model.sample_predictive_distribution(torch.tensor(x_adv_original).unsqueeze(1), 1000)\n",
    "    elif attack_model == attack_model4:\n",
    "        x_adv_original[WORSE_FEATURES] = x_adv_values[-1]\n",
    "        y_adv = model.sample_predictive_distribution(torch.tensor(x_adv_original).unsqueeze(1), 1000)\n",
    "    else:\n",
    "        y_adv = model.sample_predictive_distribution(torch.tensor(x_adv_values[-1]).unsqueeze(1), 1000)\n",
    "    func_mean = torch.exp(y_adv ** 2 / 100).mean()\n",
    "    return np.sqrt((func_mean - y_star) ** 2)\n",
    "\n",
    "\n",
    "for _ in range(4):\n",
    "    print(_)\n",
    "    losses_rep0 = []\n",
    "    losses_rep1 = []\n",
    "    losses_rep2 = []\n",
    "    losses_rep3 = []\n",
    "    losses_rep4 = []\n",
    "\n",
    "    for epsilon in epsilons:\n",
    "        losses_rep0.append(compute_loss_rep(epsilon, model))\n",
    "        losses_rep1.append(compute_loss_rep(epsilon, attack_model1))\n",
    "        losses_rep2.append(compute_loss_rep(epsilon, attack_model2))\n",
    "        losses_rep3.append(compute_loss_rep(epsilon, attack_model3))\n",
    "        losses_rep4.append(compute_loss_rep(epsilon, attack_model4))\n",
    "        \n",
    "    losses_original_rep.append(losses_rep0)\n",
    "    losses_total_rep1.append(losses_rep1)\n",
    "    losses_total_rep2.append(losses_rep2)\n",
    "    losses_total_rep3.append(losses_rep3)\n",
    "    losses_total_rep4.append(losses_rep4)\n",
    "\n",
    "# plot the mean and std of the losses\n",
    "original_mean = np.mean(losses_original_rep, axis=0)\n",
    "original_std = np.std(losses_original_rep, axis=0)\n",
    "attack1_mean = np.mean(losses_total_rep1, axis=0)\n",
    "attack1_std = np.std(losses_total_rep1, axis=0)\n",
    "attack2_mean = np.mean(losses_total_rep2, axis=0)\n",
    "attack2_std = np.std(losses_total_rep2, axis=0)\n",
    "attack3_mean = np.mean(losses_total_rep3, axis=0)\n",
    "attack3_std = np.std(losses_total_rep3, axis=0)\n",
    "attack4_mean = np.mean(losses_total_rep4, axis=0)\n",
    "attack4_std = np.std(losses_total_rep4, axis=0)\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(epsilons, np.mean(losses_original_rep, axis=0), label='Original', color='blue')\n",
    "plt.fill_between(epsilons, original_mean - original_std, original_mean + original_std, alpha=0.2, color='blue')\n",
    "plt.plot(epsilons, np.mean(losses_total_rep1, axis=0), label='Same dataset', color='orange')\n",
    "plt.fill_between(epsilons, attack1_mean - attack1_std, attack1_mean + attack1_std, alpha=0.2, color='orange')\n",
    "plt.plot(epsilons, np.mean(losses_total_rep2, axis=0), label='1/3 dataset', color='green')\n",
    "plt.fill_between(epsilons, attack2_mean - attack2_std, attack2_mean + attack2_std, alpha=0.2, color='green')\n",
    "plt.plot(epsilons, np.mean(losses_total_rep3, axis=0), label='7/11 features', color='red')\n",
    "plt.fill_between(epsilons, attack3_mean - attack3_std, attack3_mean + attack3_std, alpha=0.2, color='red')\n",
    "plt.plot(epsilons, np.mean(losses_total_rep4, axis=0), label='7/11 worse features', color='purple')\n",
    "plt.fill_between(epsilons, attack4_mean - attack4_std, attack4_mean + attack4_std, alpha=0.2, color='purple')\n",
    "plt.legend()\n",
    "plt.xlabel('$\\epsilon$')\n",
    "plt.ylabel('Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 4.5))\n",
    "plt.plot(epsilons, np.mean(losses_original_rep, axis=0), label='Original', color='blue')\n",
    "plt.fill_between(epsilons, original_mean - original_std, original_mean + original_std, alpha=0.2, color='blue')\n",
    "plt.plot(epsilons, np.mean(losses_total_rep1, axis=0), label='Same dataset', color='orange')\n",
    "plt.fill_between(epsilons, attack1_mean - attack1_std, attack1_mean + attack1_std, alpha=0.2, color='orange')\n",
    "plt.plot(epsilons, np.mean(losses_total_rep2, axis=0), label='1/3 dataset', color='green')\n",
    "plt.fill_between(epsilons, attack2_mean - attack2_std, attack2_mean + attack2_std, alpha=0.2, color='green')\n",
    "plt.plot(epsilons, np.mean(losses_total_rep3, axis=0), label='7/11 features', color='red')\n",
    "plt.fill_between(epsilons, attack3_mean - attack3_std, attack3_mean + attack3_std, alpha=0.2, color='red')\n",
    "plt.plot(epsilons, np.mean(losses_total_rep4, axis=0), label='7/11 worse features', color='purple')\n",
    "plt.fill_between(epsilons, attack4_mean - attack4_std, attack4_mean + attack4_std, alpha=0.2, color='purple')\n",
    "plt.legend()\n",
    "plt.xlabel('$\\epsilon$')\n",
    "plt.ylabel('Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print results \n",
    "print('Epsilons:', np.round(epsilons, 2))\n",
    "print(f\"Losses original: {np.round(original_mean, 2)} ± {np.round(original_std, 2)}\")\n",
    "print(f\"Losses attack with same dataset: {np.round(attack1_mean, 2)} ± {np.round(attack1_std, 2)}\")\n",
    "print(f\"Losses attack with 1/3 dataset: {np.round(attack2_mean, 2)} ± {np.round(attack2_std, 2)}\")\n",
    "print(f\"Losses attack with 7/11 best features: {np.round(attack3_mean, 2)} ± {np.round(attack3_std, 2)}\")\n",
    "print(f\"Losses attack with 7/11 worst features: {np.round(attack4_mean, 2)} ± {np.round(attack4_std, 2)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "advReg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
